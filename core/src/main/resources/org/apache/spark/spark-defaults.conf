# Default settings for Spark contexts and applications
spark {

  streaming {
    # Clock used for spark streaming operations. TODO vague
    clock = "org.apache.spark.streaming.util.SystemClock"
  }

  storage {
     memoryFraction = 0.66
  }

  cleaner {
    ttl = 3600
  }

  driver {
    # The host and port for Spark executors to communicate with driver via Akka remote
    # If there is no default host, then find out name of local host.
    host = "localhost"

    # 0 means find any open port
    port = 0
  }

  # This is very generic property used all over the code to allocate buffers. TODO: revisit
  buffer.size = 65536

  akka {
    # Sets akka.remote.netty.execution-pool-size
    threads = 4

    # akka.actor.default-dispatcher.throughput - the # of messages to handle while Actor has control
    batchSize = 15

    # akka.remote.netty.connection-timeout in seconds
    timeout = 60

    # akka.remote.netty.message-frame-size in MiB
    frameSize = 10

    # Log remote actor lifecycle events, true/false
    logLifecycleEvents = false

    # Tolerant to pauses arising out of GC pause or network reconnect.
    heartbeat.pauses = 600

    # Failure detector threshold (is set high to disable it.)
    failure-detector.threshold = 300.0

    # Heartbeat interval, is set to very high for we don't need failure detector.
    heartbeat.interval = 1000
  }

  broadcast {
    # Class used to create the broadcast variable server and client
    # Other choices include TreeBroadcastFactory and BitTorrentBroadcastFactory
    factory = org.apache.spark.broadcast.HttpBroadcastFactory

    # Compress broadcast variable transmission?
    compress = true

    blockSize = 4096
  }
}